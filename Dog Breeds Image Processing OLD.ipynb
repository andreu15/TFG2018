{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainfolder = \"train/train/\"\n",
    "Testfolder = \"test/\"\n",
    "Labelsfolder = \"labels.csv/labels.csv\"\n",
    "Samplefolder = \"sample_submission.csv/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training = pd.read_csv(Labelsfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training['image_path'] = Training.apply(lambda x: (Trainfolder + x[\"id\"] + \".jpg\" ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(Samplefolder)\n",
    "test['image_path'] = test.apply(lambda x: Testfolder + x[\"id\"] + '.jpg', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels(dim, path ):\n",
    "    image = cv2.imread(path, 1)\n",
    "    resized = cv2.resize(image, (dim, dim))\n",
    "    return resized\n",
    "\n",
    "def show_image(img):\n",
    "    cv2.imshow('gos', img)\n",
    "    cv2.waitKey()\n",
    "\n",
    "def normalize(img):\n",
    "    img  = (img-img.min())/(img.max()-img.min())\n",
    "    return np.array(img, dtype= 'float32')\n",
    "\n",
    "def save_in_hdf(df, batches = 1, s = 'X'):\n",
    "    \n",
    "    if s == 'test': np.save('testdata', df )\n",
    "    \n",
    "    else:\n",
    "        if batches == 1 :\n",
    "            if s == 'X': np.save('traindata{}'.format(s), df )\n",
    "            else:\n",
    "\n",
    "                with pd.HDFStore(\"data{}.h5\".format(s)) as hdf:\n",
    "                    hdf.put(\"training{}\".format(s), df)\n",
    "\n",
    "        else:\n",
    "\n",
    "            df1 = np.array_split(df, batches)\n",
    "\n",
    "\n",
    "            for i in range(0, batches):\n",
    "                if s == 'X': np.save('traindata{}'.format(i+1), df1[i] )\n",
    "\n",
    "                else:\n",
    "                    with pd.HDFStore(\"data{}{}.h5\".format(i+1, s)) as hdf:\n",
    "                        hdf.put(\"training{}{}\".format(i+1,s), df1[i])\n",
    "\n",
    "                print(\"Saved batch number {}\".format(i+1))\n",
    "\n",
    "                \n",
    "def load_hdf( batch_id, s = 'X'):\n",
    "    if s == 'test': df3 = np.load('testdata')\n",
    "    else:\n",
    "        if s == 'X': df3 = np.load('traindata{}.npy'.format(batch_id))       \n",
    "        else: df3 = pd.read_hdf('data{}{}.h5'.format(batch_id,s),'training{}{}'.format(batch_id,s))\n",
    "\n",
    "        print(\"Loaded batch number {}\".format(batch_id))\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_pixels(320, 'train/train/000bec180eb18c7604dcecc8fe0dba07.jpg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('train/train/000bec180eb18c7604dcecc8fe0dba07.jpg', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = normalize(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading, Preprocessing and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 99\n",
    "channels = 3\n",
    "lst = []\n",
    "for path in tqdm(Training['image_path']):\n",
    "    lst.append(normalize(get_pixels(DIM,path)))\n",
    "    \n",
    "Training[\"Data\"] = lst\n",
    "Training = pd.get_dummies(Training, columns=['breed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 99\n",
    "channels = 3\n",
    "lst2 = []\n",
    "for path in tqdm(test['image_path']):\n",
    "    lst2.append(normalize(get_pixels(DIM,path)))\n",
    "\n",
    "    \n",
    "test[\"Data\"] = lst2\n",
    "x_test = np.array(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.array(lst)\n",
    "del lst\n",
    "dropped = []\n",
    "for i in range(0,3):\n",
    "    dropped.append(Training.columns[i])\n",
    "    \n",
    "Ytrain = Training.drop(dropped, axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "num_classes = len(Ytrain.columns)\n",
    "for i in range(0, num_classes-1):\n",
    "    l = list(Ytrain.columns[i])\n",
    "    l[0:6] = []\n",
    "    elem2 = \"\".join(l)\n",
    "    dic[Ytrain.columns[i]] = elem2\n",
    "    \n",
    "Ytrain = Ytrain.rename(dic, axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_batches = 1\n",
    "save_in_hdf(Xtrain, nb_batches, 'X')\n",
    "save_in_hdf(Ytrain, nb_batches, 'Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_in_hdf(x_test, 1, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('prova.csv', header = None, names = ['col1', 'col2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
