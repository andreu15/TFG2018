{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Just run this cell to provide style to the notebook-->\n",
       "<!-- This is a code to add style to the notebook, it is based on a .css on GitHub http://bit.ly/1Bf5Hft -->\n",
       "\n",
       "<style>\n",
       "\n",
       "html {\n",
       "  font-size: 62.5% !important; }\n",
       "body {\n",
       "  font-size: 1.5em !important; /* currently ems cause chrome bug misinterpreting rems on body element */\n",
       "  line-height: 1.6 !important;\n",
       "  font-weight: 400 !important;\n",
       "  font-family: \"Raleway\", \"HelveticaNeue\", \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n",
       "  color: #222 !important; }\n",
       "\n",
       "div{ border-radius: 0px !important;  }\n",
       "div.CodeMirror-sizer{ background: rgb(244, 244, 248) !important; }\n",
       "div.input_area{ background: rgb(244, 244, 248) !important; }\n",
       "\n",
       "div.out_prompt_overlay:hover{ background: rgb(244, 244, 248) !important; }\n",
       "div.input_prompt:hover{ background: rgb(244, 244, 248) !important; }\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  color: #333 !important;\n",
       "  margin-top: 0 !important;\n",
       "  margin-bottom: 2rem !important;\n",
       "  font-weight: 300 !important;\n",
       "    text-decoration: underline;\n",
       "}\n",
       "h1 { font-size: 4.0rem !important; line-height: 1.2 !important;  letter-spacing: -.1rem !important;}\n",
       "h2 { font-size: 3.6rem !important; line-height: 1.25 !important; letter-spacing: -.1rem !important; }\n",
       "h3 { font-size: 3.0rem !important; line-height: 1.3 !important;  letter-spacing: -.1rem !important; }\n",
       "h4 { font-size: 2.4rem !important; line-height: 1.35 !important; letter-spacing: -.08rem !important; }\n",
       "h5 { font-size: 1.8rem !important; line-height: 1.5 !important;  letter-spacing: -.05rem !important; }\n",
       "h6 { font-size: 1.5rem !important; line-height: 1.6 !important;  letter-spacing: 0 !important; }\n",
       "    \n",
       "@media (min-width: 550px) {\n",
       "  h1 { font-size: 5.0rem !important; }\n",
       "  h2 { font-size: 4.2rem !important; }\n",
       "  h3 { font-size: 3.6rem !important; }\n",
       "  h4 { font-size: 3.0rem !important; }\n",
       "  h5 { font-size: 2.4rem !important; }\n",
       "  h6 { font-size: 1.5rem !important; }\n",
       "}\n",
       "\n",
       "p {\n",
       "    margin-top: 0 !important;\n",
       "    margin-bottom: 1rem !important;\n",
       "    text-align: justify;\n",
       "    text-justify: inter-word;\n",
       "    line-height: 1.5 !important;\n",
       "    font-size: 1.2em !important;\n",
       "    font-family: \"Raleway\", \"HelveticaNeue\", \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n",
       "}\n",
       "  \n",
       "a {\n",
       "  color: #1EAEDB !important; }\n",
       "a:hover {\n",
       "  color: #0FA0CE !important; }\n",
       "  \n",
       "code {\n",
       "  padding: .2rem .5rem !important;\n",
       "  margin: 0 .2rem !important;\n",
       "  font-size: 90% !important;\n",
       "  white-space: nowrap !important;\n",
       "  background: #F1F1F1 !important;\n",
       "  border: 1px solid #E1E1E1 !important;\n",
       "  border-radius: 4px !important; }\n",
       "pre > code {\n",
       "  display: block !important;\n",
       "  padding: 1rem 1.5rem !important;\n",
       "  white-space: pre !important; }\n",
       "  \n",
       "button{ border-radius: 0px !important; }\n",
       ".navbar-inner{ background-image: none !important;  }\n",
       "select, textarea{ border-radius: 0px !important; }\n",
       "    \n",
       "#Top_Header {\n",
       "    background-image: url(https://lh3.googleusercontent.com/-shldIGCRFdbscyKdAvFOATYt3wRk3SWzxQ-OSLQvvGQQEekDY2nrNYhcTl9nB3gcx_t=w300), url(https://lh3.googleusercontent.com/-shldIGCRFdbscyKdAvFOATYt3wRk3SWzxQ-OSLQvvGQQEekDY2nrNYhcTl9nB3gcx_t=w300);\n",
       "    background-size: contain;\n",
       "    background-repeat: no-repeat;\n",
       "    background-position: left, right;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    display: flex;\n",
       "    align-items: center;\n",
       "    text-align: center;\n",
       "}\n",
       "    \n",
       "</style>\n",
       "    \n",
       "<script> \n",
       "$( document ).ready(function () {\n",
       "    $(\"div#notebook-container\").children().first().hide();\n",
       "});\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<!-- Just run this cell to provide style to the notebook-->\n",
    "<!-- This is a code to add style to the notebook, it is based on a .css on GitHub http://bit.ly/1Bf5Hft -->\n",
    "\n",
    "<style>\n",
    "\n",
    "html {\n",
    "  font-size: 62.5% !important; }\n",
    "body {\n",
    "  font-size: 1.5em !important; /* currently ems cause chrome bug misinterpreting rems on body element */\n",
    "  line-height: 1.6 !important;\n",
    "  font-weight: 400 !important;\n",
    "  font-family: \"Raleway\", \"HelveticaNeue\", \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n",
    "  color: #222 !important; }\n",
    "\n",
    "div{ border-radius: 0px !important;  }\n",
    "div.CodeMirror-sizer{ background: rgb(244, 244, 248) !important; }\n",
    "div.input_area{ background: rgb(244, 244, 248) !important; }\n",
    "\n",
    "div.out_prompt_overlay:hover{ background: rgb(244, 244, 248) !important; }\n",
    "div.input_prompt:hover{ background: rgb(244, 244, 248) !important; }\n",
    "\n",
    "h1, h2, h3, h4, h5, h6 {\n",
    "  color: #333 !important;\n",
    "  margin-top: 0 !important;\n",
    "  margin-bottom: 2rem !important;\n",
    "  font-weight: 300 !important;\n",
    "    text-decoration: underline;\n",
    "}\n",
    "h1 { font-size: 4.0rem !important; line-height: 1.2 !important;  letter-spacing: -.1rem !important;}\n",
    "h2 { font-size: 3.6rem !important; line-height: 1.25 !important; letter-spacing: -.1rem !important; }\n",
    "h3 { font-size: 3.0rem !important; line-height: 1.3 !important;  letter-spacing: -.1rem !important; }\n",
    "h4 { font-size: 2.4rem !important; line-height: 1.35 !important; letter-spacing: -.08rem !important; }\n",
    "h5 { font-size: 1.8rem !important; line-height: 1.5 !important;  letter-spacing: -.05rem !important; }\n",
    "h6 { font-size: 1.5rem !important; line-height: 1.6 !important;  letter-spacing: 0 !important; }\n",
    "    \n",
    "@media (min-width: 550px) {\n",
    "  h1 { font-size: 5.0rem !important; }\n",
    "  h2 { font-size: 4.2rem !important; }\n",
    "  h3 { font-size: 3.6rem !important; }\n",
    "  h4 { font-size: 3.0rem !important; }\n",
    "  h5 { font-size: 2.4rem !important; }\n",
    "  h6 { font-size: 1.5rem !important; }\n",
    "}\n",
    "\n",
    "p {\n",
    "    margin-top: 0 !important;\n",
    "    margin-bottom: 1rem !important;\n",
    "    text-align: justify;\n",
    "    text-justify: inter-word;\n",
    "    line-height: 1.5 !important;\n",
    "    font-size: 1.2em !important;\n",
    "    font-family: \"Raleway\", \"HelveticaNeue\", \"Helvetica Neue\", Helvetica, Arial, sans-serif !important;\n",
    "}\n",
    "  \n",
    "a {\n",
    "  color: #1EAEDB !important; }\n",
    "a:hover {\n",
    "  color: #0FA0CE !important; }\n",
    "  \n",
    "code {\n",
    "  padding: .2rem .5rem !important;\n",
    "  margin: 0 .2rem !important;\n",
    "  font-size: 90% !important;\n",
    "  white-space: nowrap !important;\n",
    "  background: #F1F1F1 !important;\n",
    "  border: 1px solid #E1E1E1 !important;\n",
    "  border-radius: 4px !important; }\n",
    "pre > code {\n",
    "  display: block !important;\n",
    "  padding: 1rem 1.5rem !important;\n",
    "  white-space: pre !important; }\n",
    "  \n",
    "button{ border-radius: 0px !important; }\n",
    ".navbar-inner{ background-image: none !important;  }\n",
    "select, textarea{ border-radius: 0px !important; }\n",
    "    \n",
    "#Top_Header {\n",
    "    background-image: url(https://lh3.googleusercontent.com/-shldIGCRFdbscyKdAvFOATYt3wRk3SWzxQ-OSLQvvGQQEekDY2nrNYhcTl9nB3gcx_t=w300), url(https://lh3.googleusercontent.com/-shldIGCRFdbscyKdAvFOATYt3wRk3SWzxQ-OSLQvvGQQEekDY2nrNYhcTl9nB3gcx_t=w300);\n",
    "    background-size: contain;\n",
    "    background-repeat: no-repeat;\n",
    "    background-position: left, right;\n",
    "}\n",
    "\n",
    ".output {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    text-align: center;\n",
    "}\n",
    "    \n",
    "</style>\n",
    "    \n",
    "<script> \n",
    "$( document ).ready(function () {\n",
    "    $(\"div#notebook-container\").children().first().hide();\n",
    "});\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "//Execute this code to show the styling of the document\n",
    "$(\"div#notebook-container\").children().first().show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Top_Header\">\n",
    "    <center>\n",
    "        <h1>Dog Breed Identification</h1>\n",
    "        <h3>Deep Learning: Transfer Learning</h3>\n",
    "        <h6>Andreu Masdeu, TFG 2018</h6>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Introduction\">\n",
    "    <h2>Introduction</h2>\n",
    "    <p>This notebook is an approach to the <i>Kaggle</i> competition <strong><a href=\"https://www.kaggle.com/c/dog-breed-identification\">Dog Breed Identification</a></strong> using <i>Convolutional Neural Networks</i> and <i> Transfer Learning</i>.</p>\n",
    "    <p><i> Transfer Learning</i> is an excellence approach for problems where there isn't a large amount of data. Using pre-trained models helps us increase our accuracy, since these models are trained on datasets with millions of images. Adding our own fully connected layers to adapt these models to this particular problem is the final step for this procedure. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Importing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, Input, Conv2D, MaxPooling2D, Flatten, Dropout, LeakyReLU, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input as xcep_process\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode()\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Auxiliar functions </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The following cell includes some useful functions. Get_pixels transforms a picture into an array of numbers with the desired dimension and color channel encoding. Normalize, as its name suggests, normalizes those arrays into an interval [0,1]. Finally, show_image creates a window showing the picture given and it is useful to see differences between normalized and normal pictures. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels(dim, path ):\n",
    "    image = cv2.imread(path, 1)\n",
    "    resized = cv2.resize(image, (dim, dim))\n",
    "    return cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_image(img, dim=224):\n",
    "    #img = img.reshape((dim,dim,3))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def normalize(img):\n",
    "    img  = (img-img.min())/(img.max()-img.min())\n",
    "    return np.array(img, dtype= 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels for each photo are contained in a csv file. The following lines store in a pandas dataframe the root path and label for each picture. Finally we represent in a plot the dataset distribution for each breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = int(input(\"Write the number of pixels desired \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfolder = \"train/train/\"\n",
    "paths_labels = pd.read_csv('labels.csv/labels.csv')\n",
    "paths_labels['image_path'] = paths_labels.apply(lambda x: (trainfolder + x[\"id\"] + \".jpg\" ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = paths_labels['image_path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for path in tqdm(paths_labels['image_path']):\n",
    "    lst.append(normalize(get_pixels(DIM,path)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(paths_labels, columns=['breed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(lst)\n",
    "del lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = []\n",
    "for i in range(0,2):\n",
    "    dropped.append(labels.columns[i])\n",
    "    \n",
    "labels = labels.drop(dropped, axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "num_classes = len(labels.columns)\n",
    "for i in range(0, num_classes-1):\n",
    "    l = list(labels.columns[i])\n",
    "    l[0:6] = []\n",
    "    elem2 = \"\".join(l)\n",
    "    dic[labels.columns[i]] = elem2\n",
    "    \n",
    "labels = labels.rename(dic, axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_list = labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_for_breed = [0 for x in dogs_list]\n",
    "for label in labels_test:\n",
    "    num_for_breed[label.argmax()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Bar(\n",
    "    x=dogs_list,\n",
    "    y=num_for_breed,\n",
    "    marker=dict(\n",
    "        color='rgb(158,202,225)',\n",
    "        line=dict(\n",
    "            color='rgb(8,48,107)',\n",
    "            width=1.5,\n",
    "        )\n",
    "    ),\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "data_plot = [trace0]\n",
    "layout = go.Layout(\n",
    "    title='Breed distribution',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data_plot, layout=layout)\n",
    "py.iplot(fig, filename='text-hover-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells create three random splits on the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.1, \n",
    "                                                                    shuffle = True, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train2, data_test2, labels_train2, labels_test2 = train_test_split(data, labels, test_size=0.1, \n",
    "                                                                        shuffle = True, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train3, data_test3, labels_train3, labels_test3 = train_test_split(data, labels, test_size=0.1,\n",
    "                                                                        shuffle = True, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Neural Network architecture </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In Keras, pre-trained models are stored in <i>keras.applications</i> and are treated as layers when designing a network. As we call <i>model.add(Convolution(...)</i>, we would call <i>model.add(Xception(...))</i>. Paremeters for that method are: weights, include_top and input_shape. </p>\n",
    "    \n",
    "<p> We can decide whether to use the pretrained weights by calling <i>weights = 'imagenet' </i>  or just stick with the structure and randomly initialize them. Include_top makes reference to include the fully connected layers in the model or not. Usually, in transfer learning, these layers are not included because the output layer differs and we are predicting new classes. Finally, input_shape is the dimension of your images in the classic format [height, width, channels]. There are default dimensions in which the models were trained, but any dimension can be used. The layer would automatically infer changes on the convolutions, poolings etc...   </p>\n",
    "\n",
    "<p> We opted for using default dimensions for each model. First of all, we define a function that returns the model we will use. Once we get the model, since the output shape is a 3D tensor we flatten it. Then, an undefined number of fully connected layers are added, each one with dropout, batch normalization and leaky relu as activation function. The output layer is the final one, and since this is classification problem we use softmax. Finally, we compile it, and we use categorical cross entropy as our loss function since we are using the softmax activation. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freezing weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we train the frozen model. The first cells extract the high-level features from the images. Then we define the feedforward network in the function freeze_model. Finally, we train a copy of that model for each dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Xception(weights='imagenet', include_top=False, input_shape=(DIM, DIM, 3), pooling = 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = []\n",
    "feature_vectors_val = []\n",
    "for elem in data_train:\n",
    "    feature_vectors.append(feature_extractor.predict(elem.reshape(1, 299, 299, 3)).reshape(2048))\n",
    "    \n",
    "for elem in data_test:\n",
    "    feature_vectors_val.append(feature_extractor.predict(elem.reshape(1, 299, 299, 3)).reshape(2048))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors2 = []\n",
    "feature_vectors_val2 = []\n",
    "for elem in data_train2:\n",
    "    feature_vectors2.append(feature_extractor.predict(elem.reshape(1, 299, 299, 3)).reshape(2048))\n",
    "    \n",
    "for elem in data_test2:\n",
    "    feature_vectors_val2.append(feature_extractor.predict(elem.reshape(1, 299, 299, 3)).reshape(2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors3 = []\n",
    "feature_vectors_val3 = []\n",
    "for elem in data_train3:\n",
    "    feature_vectors3.append(feature_extractor.predict(elem.reshape(1, 299, 299, 3)).reshape(2048))\n",
    "    \n",
    "for elem in data_test3:\n",
    "    feature_vectors_val3.append(feature_extractor.predict(elem.reshape(1, 299, 299, 3)).reshape(2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model( nhid = 3, drop = 0, alpha = 0.05):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if nhid != 0:\n",
    "        model.add(Dense(int(512), input_shape = (2048,)))\n",
    "        model.add(LeakyReLU(alpha = alpha))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(drop))\n",
    "    \n",
    "    for i in range(0,nhid-1):\n",
    "        model.add(Dense(int(216/(2 ** i))))\n",
    "        model.add(LeakyReLU(alpha = alpha))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(drop))\n",
    "        \n",
    "    if nhid == 0: model.add(Dense(120, activation = 'softmax', input_shape=(2048,)))\n",
    "    else: model.add(Dense(120, activation = 'softmax'))\n",
    "        \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_freeze = freeze_model(nhid =0 , drop = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_freeze.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_freeze = model_freeze.fit(np.array(feature_vectors), labels_train, batch_size = 16, epochs = 16, callbacks = [], \n",
    "                    validation_data = (np.array(feature_vectors_val), labels_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_freeze2 = freeze_model(nhid =0 , drop = 0.2)\n",
    "history_freeze2 = model_freeze2.fit(np.array(feature_vectors2), labels_train2, batch_size = 16, epochs = 16, callbacks = [], \n",
    "                    validation_data = (np.array(feature_vectors_val2), labels_test2), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_freeze3 = freeze_model(nhid =0 , drop = 0.2)\n",
    "history_freeze3 = model_freeze3.fit(np.array(feature_vectors3), labels_train3, batch_size = 16, epochs = 16, callbacks = [], \n",
    "                    validation_data = (np.array(feature_vectors_val3), labels_test3), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we train the frozen model using data augmentation. The first cell creates the data augmentation generator using the keras function ImageDataGenerator. We set values for rotation, shift, zoom and flip. Then we define the frozen model including Xception as one layer more. But we set the Xception layer to a non-trainable state to keep the weights frozen. Then we train three samples of this model using the three splits and with the method fit_generator, as we use the python generator created for artificially augmenting the number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "datagen.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_gen_model( nhid = 3, drop = 0, alpha = 0.05):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Xception(weights='imagenet', include_top=False, input_shape=(DIM, DIM, 3), pooling = 'avg'))\n",
    "    \n",
    "    for i in range(0,nhid):\n",
    "        model.add(Dense(int(512/(2 ** i))))\n",
    "        model.add(LeakyReLU(alpha = alpha))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(drop))\n",
    "        \n",
    "    model.add(Dense(120, activation = 'softmax'))\n",
    "    \n",
    "    model.layers[0].trainable = False\n",
    "        \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_freeze_gen = freeze_gen_model(nhid = 0, drop = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_freeze_gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_freeze_gen = model_freeze_gen.fit_generator(datagen.flow(data_train, labels_train, batch_size = 16), epochs = 16,\n",
    "                                       steps_per_epoch = data_train.shape[0]//16,\n",
    "                                       validation_data = (data_test, labels_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_freeze_gen2 = freeze_gen_model(nhid = 0, drop = 0.0)\n",
    "history_freeze_gen2 = model_freeze_gen2.fit_generator(datagen.flow(data_train2, labels_train2, batch_size = 16), epochs = 16,\n",
    "                                       steps_per_epoch = data_train.shape[0]//16,\n",
    "                                       validation_data = (data_test2, labels_test2), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_freeze_gen3 = freeze_gen_model(nhid = 0, drop = 0.0)\n",
    "history_freeze_gen3 = model_freeze_gen3.fit_generator(datagen.flow(data_train3, labels_train3, batch_size = 16), epochs = 16,\n",
    "                                       steps_per_epoch = data_train.shape[0]//16,\n",
    "                                       validation_data = (data_test3, labels_test3), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Fine-tuning </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we train the fine-tuning model. We define the fine-tuning model including Xception as one layer more. Then we train three samples of this model using the three splits and with the method fit_generator, as we use the python generator created for artificially augmenting the number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_model( nhid = 3, drop = 0, alpha = 0.05):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Xception(weights='imagenet', include_top=False, input_shape=(DIM, DIM, 3), pooling = 'avg'))\n",
    "    \n",
    "    for i in range(0,nhid):\n",
    "        model.add(Dense(int(512/(2 ** i))))\n",
    "        model.add(LeakyReLU(alpha = alpha))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(drop))\n",
    "        \n",
    "    model.add(Dense(120, activation = 'softmax'))\n",
    "        \n",
    "    adam_opt = keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=adam_opt, loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine = fine_model(nhid = 0, drop = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fine = model_fine.fit(data_train, labels_train, batch_size = 16, epochs = 16, callbacks = [], \n",
    "                    validation_data = (data_test, labels_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine2 = fine_model(nhid = 0, drop = 0.0)\n",
    "history_fine2 = model_fine2.fit(data_train2, labels_train2, batch_size = 16, epochs = 16, callbacks = [], \n",
    "                    validation_data = (data_test2, labels_test2), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine3 = fine_model(nhid = 0, drop = 0.0)\n",
    "history_fine3 = model_fine3.fit(data_train3, labels_train3, batch_size = 16, epochs = 16, callbacks = [], \n",
    "                    validation_data = (data_test3, labels_test3), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we train the fine-tuning model using data augmentation. The first cell creates the data augmentation generator using the keras function ImageDataGenerator. We set values for rotation, shift, zoom and flip. Then we define the fine-tuning model including Xception as one layer more. Then we train three samples of this model using the three splits and with the method fit_generator, as we use the python generator created for artificially augmenting the number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "datagen.fit(data_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = fine_model(nhid = 0, drop = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fine_gen = model_gen.fit_generator(datagen.flow(data_train, labels_train, batch_size = 16), epochs = 16,\n",
    "                                       steps_per_epoch = data_train.shape[0]//16,\n",
    "                                       validation_data = (data_test, labels_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen2 = fine_model(nhid = 0, drop = 0.0)\n",
    "history_fine_gen2 = model_gen2.fit_generator(datagen.flow(data_train2, labels_train2, batch_size = 16), epochs = 16,\n",
    "                                       steps_per_epoch = data_train.shape[0]//16,\n",
    "                                     jg  validation_data = (data_test2, labels_test2), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen3 = fine_model(nhid = 0, drop = 0.0)\n",
    "history_fine_gen3 = model_gen3.fit_generator(datagen.flow(data_train3, labels_train3, batch_size = 16), epochs = 16,\n",
    "                                       steps_per_epoch = data_train3.shape[0]//16,\n",
    "                                       validation_data = (data_test3, labels_test3), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Plotting </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, a useful way of checking our model's performance is by plotting accuracy and loss. We'll do it for the 4 approaches in the first split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis1 = history_freeze.history['acc']\n",
    "y_axis2 = history_freeze.history['val_acc']\n",
    "y_axis3 = history_freeze.history['loss']\n",
    "y_axis4 = history_freeze.history['val_loss']\n",
    "x_axis = list(range(1,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = x_axis, y = y_axis1, mode = 'lines+markers', name = 'Training accuracy')\n",
    "\n",
    "trace2 = go.Scatter(x = x_axis, y = y_axis2, mode = 'lines+markers', name = 'Validation accuracy')\n",
    "\n",
    "data1 = [trace1, trace2]\n",
    "\n",
    "py.iplot(data1, filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace2 = go.Scatter(x = x_axis, y = y_axis3, mode = 'lines+markers', name = 'Training loss')\n",
    "\n",
    "trace3 = go.Scatter(x = x_axis, y = y_axis4, mode = 'lines+markers', name = 'Validation loss')\n",
    "\n",
    "data2 = [trace2, trace3]\n",
    "\n",
    "py.iplot(data2, filename='basic-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze using data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis1 = history_freeze_gen.history['acc']\n",
    "y_axis2 = history_freeze_gen.history['val_acc']\n",
    "y_axis3 = history_freeze_gen.history['loss']\n",
    "y_axis4 = history_freeze_gen.history['val_loss']\n",
    "x_axis = list(range(1,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = x_axis, y = y_axis1, mode = 'lines+markers', name = 'Training accuracy')\n",
    "\n",
    "trace2 = go.Scatter(x = x_axis, y = y_axis2, mode = 'lines+markers', name = 'Validation accuracy')\n",
    "\n",
    "\n",
    "data1 = [trace1, trace2]\n",
    "\n",
    "py.iplot(data1, filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace2 = go.Scatter(x = x_axis, y = y_axis3, mode = 'lines+markers', name = 'Training loss')\n",
    "\n",
    "trace3 = go.Scatter(x = x_axis, y = y_axis4, mode = 'lines+markers', name = 'Validation loss')\n",
    "\n",
    "data2 = [trace2, trace3]\n",
    "\n",
    "py.iplot(data2, filename='basic-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis1 = history_fine.history['acc']\n",
    "y_axis2 = history_fine.history['val_acc']\n",
    "y_axis3 = history_fine.history['loss']\n",
    "y_axis4 = history_fine.history['val_loss']\n",
    "x_axis = list(range(1,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = x_axis, y = y_axis1, mode = 'lines+markers', name = 'Training accuracy')\n",
    "\n",
    "trace2 = go.Scatter(x = x_axis, y = y_axis2, mode = 'lines+markers', name = 'Validation accuracy')\n",
    "\n",
    "data1 = [trace1, trace2]\n",
    "\n",
    "py.iplot(data1, filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace2 = go.Scatter(x = x_axis, y = y_axis3, mode = 'lines+markers', name = 'Training loss')\n",
    "\n",
    "trace3 = go.Scatter(x = x_axis, y = y_axis4, mode = 'lines+markers', name = 'Validation loss')\n",
    "\n",
    "data2 = [trace2, trace3]\n",
    "\n",
    "py.iplot(data2, filename='basic-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis1 = history_fine_gen3.history['acc']\n",
    "y_axis2 = history_fine_gen3.history['val_acc']\n",
    "y_axis3 = history_fine_gen3.history['loss']\n",
    "y_axis4 = history_fine_gen3.history['val_loss']\n",
    "x_axis = list(range(1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = x_axis, y = y_axis1, mode = 'lines+markers', name = 'Training accuracy')\n",
    "\n",
    "trace2 = go.Scatter(x = x_axis, y = y_axis2, mode = 'lines+markers', name = 'Validation accuracy')\n",
    "\n",
    "data1 = [trace1, trace2]\n",
    "\n",
    "py.iplot(data1, filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace2 = go.Scatter(x = x_axis, y = y_axis3, mode = 'lines+markers', name = 'Training loss')\n",
    "\n",
    "trace3 = go.Scatter(x = x_axis, y = y_axis4, mode = 'lines+markers', name = 'Validation loss')\n",
    "\n",
    "data2 = [trace2, trace3]\n",
    "\n",
    "py.iplot(data2, filename='basic-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since training takes so long, it is wise to save the model if results were interesting. Also, we need the weights and the architecture in a file for uploading them into the AWS Lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models = [model_freeze,  model_freeze_gen, \n",
    "               model_fine,  model_gen, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model1 in enumerate(list_models):\n",
    "    model_json = model1.model.to_json()\n",
    "    with open(\"model_architecture{}.json\".format(i), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model1.model.save_weights(\"model_weights{}.h5\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_architecture3.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model3 = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "\n",
    "model3.load_weights(\"model_weights3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are used for validating the model. First of all, we define the function get_dog which returns the name of the dog given the probability vector. Then we define the function, check_some_dogs which let us visualize the model on real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def get_dog(v):\n",
    "    \n",
    "    return dogs_list[v.argmax()]\n",
    "\n",
    "def check_some_dogs(model, paths, labels):\n",
    "    \n",
    "    errors = 0\n",
    "    for i in range(0, len(paths)):\n",
    "                \n",
    "        img = normalize(get_pixels(299, paths[i]))\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        pred = model.predict(img.reshape((1,299,299,3)))\n",
    "        dog = get_dog(pred)\n",
    "        print(\"Correct label: \", get_dog(labels[i]), \"  \")\n",
    "        print(\"Predicted label: \", dog , \"  \")\n",
    "        print(\"Probability: \", pred.max()*100, '% ')\n",
    "        \n",
    "        if dog != get_dog(labels[i]): errors = errors + 1\n",
    "        \n",
    "        time.sleep(2)\n",
    "        if i != len(paths)-1: clear_output()\n",
    "        \n",
    "    print(\"Checked {} images\".format(len(paths)), \"  \")\n",
    "    print(\"Estimated accuracy: \", 100-100*errors/len(paths), \"%   \" )\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_some_dogs(model, paths[500:560], labels[500:560])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells implement methods for visualizing confusion matrices and the F1-Score for each class. First of all, we import the sklearn function, confusion_matrix, which builds a confusion matrix using the predicted labels and the true labels. Then we define functions for computing, recall and precision from the confusion matrix. Once we have this functions we can define the F1-Score. Also, we defined a function for visualizating the confusion matrices, plot_conf_mat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def recall_fun(conf_mat):\n",
    "    \n",
    "    recall_list=[]\n",
    "    size_mat = len(conf_mat)\n",
    "    \n",
    "    for i in range(0,size_mat):\n",
    "        true_positive = 0\n",
    "        false_negative = 0\n",
    "        for j in range(0,size_mat):\n",
    "            if(i==j): true_positive = conf_mat[i,j]\n",
    "            else: false_negative += conf_mat[i,j]\n",
    "        if true_positive+false_negative == 0: recall_k = 0\n",
    "        else:\n",
    "            recall_k = true_positive/(true_positive+false_negative)\n",
    "        recall_list.append(recall_k)\n",
    "        \n",
    "    return recall_list\n",
    "\n",
    "def precision_fun(conf_mat):\n",
    "    \n",
    "    precision_list=[]\n",
    "    size_mat = len(conf_mat)\n",
    "    \n",
    "    for j in range(0,size_mat):\n",
    "        true_positive = 0\n",
    "        false_positive = 0\n",
    "        for i in range(0,size_mat):\n",
    "            if(i==j): true_positive = conf_mat[i,j]\n",
    "            else: false_positive += conf_mat[i,j]\n",
    "                \n",
    "        if true_positive+false_positive == 0: precision_k = 0\n",
    "        else:\n",
    "            precision_k = true_positive/(true_positive+false_positive)\n",
    "        precision_list.append(precision_k)\n",
    "        \n",
    "    return precision_list\n",
    "\n",
    "def F1_score(conf_mat, mode = 1):\n",
    "    recall = recall_fun(conf_mat)\n",
    "    precision = precision_fun(conf_mat)\n",
    "    \n",
    "    size_mat = len(conf_mat)\n",
    "    F1 = 0\n",
    "    f1 = []\n",
    "    \n",
    "    for i in range(0,size_mat):\n",
    "        if precision[i]+recall[i] == 0: f1_k = 0\n",
    "            \n",
    "        else: \n",
    "            f1_k = (2*precision[i]*recall[i]) / (precision[i]+recall[i])\n",
    "            F1 += f1_k\n",
    "        if mode: \n",
    "            print('F1 score for {} is {} '.format(dogs_list[i], f1_k ))\n",
    "            print('')\n",
    "            print('Precision: {}, Recall: {} '.format(precision[i], recall[i]))\n",
    "            print('')\n",
    "        f1.append(f1_k)\n",
    "        \n",
    "    print('Mean F1 score is {}'.format(F1/size_mat))  \n",
    "    return F1/size_mat, f1\n",
    "\n",
    "def plot_confusion_mat(model, images, labels, mode = 1):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for i in range(0, len(images)):\n",
    "        \n",
    "        if mode: dog = get_dog(model.predict(images[i].reshape(1,299, 299, 3)))\n",
    "        else: dog = get_dog(model.predict(images[i].reshape(1,2048)))\n",
    "        true_labels.append(get_dog(labels[i]))\n",
    "        predicted_labels.append(dog)\n",
    "                          \n",
    "    matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    classes = dogs_list\n",
    "    trace = go.Heatmap(z=matrix,\n",
    "                    colorscale=\"Greens\", reversescale=True)\n",
    "    \n",
    "    layout = go.Layout( title='Confusion Matrix', xaxis={'title':'Predicted Classes'}, yaxis={'title':'True Classes'})\n",
    "    \n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "    py.iplot(fig, filename='labelled-heatmap', show_link=False)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices and F1-Scores for the freeze approach using data augmentation and the fine-tuning approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_list = []\n",
    "\n",
    "list_models = [model, model2, model3]\n",
    "\n",
    "for model in list_models:\n",
    "    \n",
    "    conf_mat = plot_confusion_mat(model, data_test, labels_test)\n",
    "    conf_mat_list.append(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf_mat in conf_mat_list:\n",
    "    F1_score(conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf_mat in conf_mat_list:\n",
    "    mean, f1_components = F1_score(conf_mat, 0)\n",
    "    trace = go.Scatter(x = dogs_list, y = f1_components, mode = 'lines+markers', name = 'F1 score per class')\n",
    "\n",
    "\n",
    "    data = [trace]\n",
    "    \n",
    "    layout = dict(title = 'F1 Score',\n",
    "              yaxis = dict(zeroline = False),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='basic-line')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze approach: confusion matrix and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = plot_confusion_mat(model_freeze, feature_vectors_val, labels_test, 0)\n",
    "mean, f1_components = F1_score(conf_mat, 0)\n",
    "trace = go.Scatter(x = dogs_list, y = f1_components, mode = 'lines+markers', name = 'F1 score per class')\n",
    "\n",
    "\n",
    "data = [trace]\n",
    "    \n",
    "layout = dict(title = 'F1 Score',\n",
    "              yaxis = dict(zeroline = False),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_list = y_train.columns.tolist()\n",
    "\n",
    "print(dogs_list[model.predict(normalize(get_pixels(299, 'bond.jpg')).reshape((1,299,299,3))).argmax()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
